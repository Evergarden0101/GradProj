# 系统需求

---

## 问题

### 系统形式

- 以网站或软件的形式部署在服务器上，获取服务器上的日志信息









---

## 用户识别

- 用户识别主要是为了识别出日志信息中的不同用户，方便后续将相同用户的访问信息
  归并为行为序列进行挖掘。
  - 用户ID
  - IP地址



---

## 爬虫识别

- block易于访问的主机和代理服务
  - DIGITAL OCEAN 
  - GIGENET
  - OVH HOSTING
  - CHOOPA, LLC
- 流量高峰
- 失败的登录尝试
- 验证失败
- 设置单位阈值目的在于识别。单位阈值：在任何单位时间内所允许的最高或最低值。倘若某一IP、user_agent标识超出了阈值，对其实施监控
- robots.txt



---

## 流量控制

- 在某些情况下，外国访问者使用一个网站是没有意义的，可以屏蔽大量的外国IP地址。

  - 在其他情况下，遭受来自无法产生大量流量的国家的攻击，可以屏蔽来自该国家的所有流量作为一种明智的保护措施。

- 获取到非正常用户时，还可以重定向。
  将用户页面返回到验证页面。常见的有验证码验证、语音验证、短信验证、邮箱验证。

- 增加了注册登录是可以有效阻止爬虫访问的。

- 阻塞过时的用户代理/浏览器的风险非常低;大多数现代浏览器强制用户进行自动更新，这使得使用过时版本浏览网页变得更加困难。

- |                           | **BLOCK**<br/>End of Life<br/>More than 3 years<br/> | **CAPCHA**<br/>End of Life<br/>More than 2 years |
  | ------------------------- | ---------------------------------------------------- | :----------------------------------------------- |
  | Firefox version           | <52                                                  | <60                                              |
  | Chrome version            | <57                                                  | <65                                              |
  | Internet Explorer version | <10                                                  | <10                                              |
  | Safari version            | <9                                                   | <9                                               |

- 



---

## 参考文献

- A System Framework for Efficiently Recognizing Web Crawlers	
  - 机器学习反爬虫
  - 使用日志
  - 训练阶段
  - 对会话提取三个特征=标记数据
    - 会话的身份信息
    - 日志的统计信息
    - 日志中的异常信息
  - 会话数据做训练集
  - 在分类阶段，对等待检查的访问请求进行会话分割和特征提取。
    - 所产生的会话特性被输入到分类器中，以确定它是来自web爬虫还是人。
- Research on an anti-crawling mechanism and key algorithm based on sliding time window
  - 基于滑动时间窗的爬虫实时检测方法，提高了对不符合爬虫规则的检测的准确性和效率。

- SpiderTrap—An Innovative Approach to Analyze Activity of Internet Bots on a Website
  - SpiderTrap记录HTTP请求，并了解使用honeypot在陷阱的网站上生成的链接之间的关系，足以跟踪许多种类的机器人，甚至是更复杂的机器人。使用一个简单的规则列表，可以将请求分类为恶意或非恶意。合并这两种类型的数据给能够创建规则适用于web服务器或web应用程序防火墙过滤不必要的机器人。
- Predicting user behavior through sessions using the web log mining
  - 处理log日志以获取

